git clone git@github.com:apache/incubator-doris.git

安装:
https://doris.apache.org/master/zh-CN/installing/compilation.html#%E4%BD%BF%E7%94%A8-docker-%E5%BC%80%E5%8F%91%E9%95%9C%E5%83%8F%E7%BC%96%E8%AF%91%EF%BC%88%E6%8E%A8%E8%8D%90%EF%BC%89
rowset_meta.h:29:10: fatal error: json2pb/json_to_pb.h


容器编译环境:
docker run -it -v /home/xiaoxing/idea-workspace/incubator-doris:/home/xiaoxing/idea-workspace/incubator-doris -v /home/xiaoxing/.m2/:/root/.m2 apachedoris/doris-dev:build-env-1.2 bash

源码下载:
wget https://dist.apache.org/repos/dist/dev/incubator/doris/0.9/0.9.0-incubating-rc02/apache-doris-0.9.0.rc02-incubating-src.tar.gz
ubuntu编译第三方依赖缺少:
/var/local/thirdparty/installed/include/butil/containers/flat_map.h
/var/local/thirdparty/installed/include/bthread/
/var/local/thirdparty/installed/include/bvar
/var/local/thirdparty/installed/include/arrow
/var/local/thirdparty/installed/include/parquet

/var/local/thirdparty/installed/lib64/libparquet.a

调试环境:
http://doris.incubator.apache.org/master/zh-CN/developer-guide/debug-tool.html#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87

clion中cmake导入环境变量:
DORIS_THIRDPARTY=/var/local/thirdparty;DORIS_GCC_HOME=/usr
/home/xiaoxing/clion-2020.2.1/bin/cmake/linux/bin/cmake -DCMAKE_BUILD_TYPE=Debug -G "CodeBlocks - Unix Makefiles" /home/xiaoxing/idea-workspace/incubator-doris/be

/home/xiaoxing/clion-2020.2.1/bin/cmake/linux/bin/cmake --build /home/xiaoxing/idea-workspace/incubator-doris/be/cmake-build-debug --target palo_be -- -j 6

需要解决异常:
/var/local/thirdparty/installed//lib/libcurl.a(libcurl_la-http2.o):http2.c:(.text+0x52f): 跟着更多未定义的参考到 nghttp2_session_get_stream_user_data
/var/local/thirdparty/installed//lib/libcurl.a(libcurl_la-openssl.o)：在函数‘ossl_connect_step1’中：
openssl.c:(.text+0xb71)：对‘TLS_client_method’未定义的引用

开发环境:
http://doris.incubator.apache.org/master/zh-CN/developer-guide/fe-idea-dev.html#_1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87

使用: -Dlog4j2.debug
master: $DORIS_HOME/fe/doris-meta/
org.apache.doris.PaloFe
查看是否成功:http://localhost:8030/api/bootstrap
http://localhost:8030/system?path=//frontends 

worker: $DORIS_HOME/be/storage
$DORIS_HOME/be/lib/palo_be
bin/start_be.sh --daemon

planner -> coordinator

http://doris.apache.org/master/zh-CN/getting-started/basic-usage.html#_3-%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9F%A5%E8%AF%A2
 注意：慎用mysql-workbench, 在启动的时候会发送查询sql导致没有backend报错
mysql -h172.26.160.38 -P9030 -u root
新增backend: (ip:heartbeat_service_port)
alter system add backend "172.26.160.38:9050";
查看backend:
show proc '/backends';

create database test_doris;
建表：
CREATE TABLE table1
(
    siteid INT DEFAULT '10',
    citycode SMALLINT,
    username VARCHAR(32) DEFAULT '',
    pv BIGINT SUM DEFAULT '0'
)
AGGREGATE KEY(siteid, citycode, username)
DISTRIBUTED BY HASH(siteid) BUCKETS 10
PROPERTIES("replication_num" = "1");

CREATE USER 'test' IDENTIFIED BY 'test_passwd';
GRANT ALL ON test_doris TO test;

cat table1.data:
1,1,jim,2
2,1,grace,2
3,2,tom,2
4,3,bush,3
5,3,helen,3
curl -v --location-trusted -u test:test_passwd -H "label:table1_20170707" -H "column_separator:," -T table1.data http://172.26.160.38:8030/api/test_doris/table1/_stream_load

CREATE TABLE table2
(
    event_day DATE,
    siteid INT DEFAULT '10',
    citycode SMALLINT,
    username VARCHAR(32) DEFAULT '',
    pv BIGINT SUM DEFAULT '0'
)
AGGREGATE KEY(event_day, siteid, citycode, username)
PARTITION BY RANGE(event_day)
(
    PARTITION p201706 VALUES LESS THAN ('2017-07-01'),
    PARTITION p201707 VALUES LESS THAN ('2017-08-01'),
    PARTITION p201708 VALUES LESS THAN ('2017-09-01')
)
DISTRIBUTED BY HASH(siteid) BUCKETS 10
PROPERTIES("replication_num" = "1");

cat table2.data:
2017-07-03|1|1|jim|2
2017-07-05|2|1|grace|2
2017-07-12|3|2|tom|2
2017-07-15|4|3|bush|3
2017-07-12|5|3|helen|3
curl --location-trusted -u test:test_passwd -H "label:table2_20170707" -H "column_separator:|" -T table2.data http://127.0.0.1:8030/api/test_doris/table2/_stream_load

 SELECT SUM(table1.pv) FROM table1 JOIN table2 WHERE table1.siteid = table2.siteid;
 SELECT SUM(pv) FROM table2 WHERE siteid IN (SELECT siteid FROM table1 WHERE siteid > 2);

spark load流程:
http://doris.apache.org/master/zh-CN/administrator-guide/load-data/spark-load-manual.html#%E5%88%9B%E5%BB%BA%E5%AF%BC%E5%85%A5

启动配置broker: 将apache_hdfs_broker.conf, apache_hdfs_broker.jar(来自doris里的incubator-doris/fs_brokers), start_broker.sh放到fe下的对应conf,lib,bin下
bin/start_broker.sh

alter system add broker  broker1 "172.26.160.38:8000";
show proc '/brokers';
CREATE EXTERNAL RESOURCE "spark2"
PROPERTIES
(
  "type" = "spark",
  "spark.master" = "spark://127.0.0.1:7077",
  "spark.submit.deployMode" = "client",
  "working_dir" = "hdfs://127.0.0.1:8020/tmp/doris",
  "broker" = "broker1"
);
show proc '/resources';

导入数据:
use test_doris;
create table tbl1(id int, name varchar(255)) DISTRIBUTED BY HASH(id) BUCKETS 10 PROPERTIES("replication_num" = "1");
create table tbl2(col1 varchar(255), col2 varchar(255)) DISTRIBUTED BY HASH(col1) BUCKETS 10 PROPERTIES("replication_num" = "1");
LOAD LABEL test_doris.label1
(
    DATA INFILE("hdfs://localhost:8020/user/palo/test/ml/file1")
    INTO TABLE tbl1
    COLUMNS TERMINATED BY ","
    (tmp_c1,tmp_c2)
    SET
    (
        id=tmp_c2,
        name=tmp_c1
    ),
    DATA INFILE("hdfs://localhost:8020/user/palo/test/ml/file2")
    INTO TABLE tbl2
    COLUMNS TERMINATED BY ","
    (col1, col2)
    where col1 > 1
)
WITH RESOURCE 'spark2'
(
    "spark.executor.memory" = "1g",
    "spark.shuffle.compress" = "true"
)
PROPERTIES
(
    "timeout" = "3600"
);

查看任务执行结果:
show load order by createtime desc limit 1\G;